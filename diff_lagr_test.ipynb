{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rotogni/diffusion-lagr/blob/google_colab/diff_lagr_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q39cPihdbc1",
        "outputId": "5c04a48b-4915-422d-dab3-6883c2bf1cd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Mar 28 15:12:17 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   37C    P8             11W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Your runtime has 56.9 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "Ps1TgS_kMgFh",
        "outputId": "3bb3fe76-b4f5-4671-8a09-465f5333031a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create the 'diff-lagr' directory first\n",
        "os.makedirs('/content/drive/My Drive/diff-lagr', exist_ok=True)\n",
        "\n",
        "# Then create the subdirectories\n",
        "os.makedirs('/content/drive/My Drive/diff-lagr/model_checkpoints', exist_ok=True)\n",
        "os.makedirs('/content/drive/My Drive/diff-lagr/samples', exist_ok=True)"
      ],
      "metadata": {
        "id": "8FQNT1OBNsEB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "id": "GZY3Y6jFUSWK",
        "outputId": "8ed6b215-7527-41b0-ee00-6703d24d88ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNbRj0xHZNDY",
        "outputId": "34441543-34c4-482d-f5d0-7e619d7c3995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libopenmpi-dev is already the newest version (4.1.2-2ubuntu1).\n",
            "openmpi-bin is already the newest version (4.1.2-2ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "Requirement already satisfied: mpi4py in /usr/local/lib/python3.11/dist-packages (4.0.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.13.0)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from h5py) (2.0.2)\n",
            "Cloning into 'diffusion-lagr'...\n",
            "remote: Enumerating objects: 498, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 498 (delta 63), reused 34 (delta 27), pack-reused 418 (from 3)\u001b[K\n",
            "Receiving objects: 100% (498/498), 1.26 GiB | 17.05 MiB/s, done.\n",
            "Resolving deltas: 100% (182/182), done.\n",
            "Updating files: 100% (179/179), done.\n",
            "/content/diffusion-lagr\n",
            "Obtaining file:///content/diffusion-lagr\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting blobfile>=1.0.5 (from guided-diffusion==0.0.0)\n",
            "  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from guided-diffusion==0.0.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from guided-diffusion==0.0.0) (4.67.1)\n",
            "Collecting pycryptodomex>=3.8 (from blobfile>=1.0.5->guided-diffusion==0.0.0)\n",
            "  Downloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from blobfile>=1.0.5->guided-diffusion==0.0.0) (2.3.0)\n",
            "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.11/dist-packages (from blobfile>=1.0.5->guided-diffusion==0.0.0) (5.3.1)\n",
            "Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.11/dist-packages (from blobfile>=1.0.5->guided-diffusion==0.0.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->guided-diffusion==0.0.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->guided-diffusion==0.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->guided-diffusion==0.0.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->guided-diffusion==0.0.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->guided-diffusion==0.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->guided-diffusion==0.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->guided-diffusion==0.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->guided-diffusion==0.0.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->guided-diffusion==0.0.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->guided-diffusion==0.0.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->guided-diffusion==0.0.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->guided-diffusion==0.0.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->guided-diffusion==0.0.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->guided-diffusion==0.0.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->guided-diffusion==0.0.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->guided-diffusion==0.0.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->guided-diffusion==0.0.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->guided-diffusion==0.0.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->guided-diffusion==0.0.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->guided-diffusion==0.0.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->guided-diffusion==0.0.0) (3.0.2)\n",
            "Downloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycryptodomex, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, blobfile, nvidia-cusolver-cu12, guided-diffusion\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Running setup.py develop for guided-diffusion\n",
            "Successfully installed blobfile-3.0.0 guided-diffusion-0.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pycryptodomex-3.22.0\n",
            "guided_diffusion installed successfully\n"
          ]
        }
      ],
      "source": [
        "# Set up environment for guided diffusion project\n",
        "!apt-get update\n",
        "!apt-get install -y libopenmpi-dev openmpi-bin\n",
        "!pip install mpi4py\n",
        "!CC=mpicc CXX=mpicxx pip install --no-binary=h5py h5py\n",
        "\n",
        "# Clone the repository (replace with the actual repo URL)\n",
        "!git clone -b google_colab https://github.com/rotogni/diffusion-lagr.git\n",
        "%cd diffusion-lagr\n",
        "\n",
        "# Install the package in development mode\n",
        "!pip install -e .\n",
        "\n",
        "# Verify installation\n",
        "!python -c \"import guided_diffusion; print('guided_diffusion installed successfully')\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xdUzWG_WaWzA"
      },
      "outputs": [],
      "source": [
        "# Set the flags\n",
        "DATA_FLAGS=\"--dataset_path datasets/trajectories_zero_padding_prenormalise.h5 --dataset_name train\"\n",
        "MODEL_FLAGS=\"--dims 1 --image_size 300 --in_channels 3 --num_channels 32 --num_res_blocks 2 --attention_resolutions 150,75 --channel_mult 1,2,4\"\n",
        "DIFFUSION_FLAGS=\"--diffusion_steps 800 --noise_schedule tanh6,1\"\n",
        "TRAIN_FLAGS=\"--lr 1e-4 --batch_size 8 --lr_anneal_steps 500000 --save_interval 10000\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oaf6UGwEafvX",
        "outputId": "d5efab6d-427b-4681-c7c8-3648200bb26b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging to /tmp/openai-2025-03-28-15-23-12-003364\n",
            "creating model and diffusion...\n",
            "creating data loader...\n",
            "training...\n",
            "-------------------------\n",
            "| grad_norm  | 0.803    |\n",
            "| loss       | 0.994    |\n",
            "| loss_q0    | 0.967    |\n",
            "| loss_q1    | 0.959    |\n",
            "| loss_q2    | 0.986    |\n",
            "| loss_q3    | 1.06     |\n",
            "| mse        | 0.994    |\n",
            "| mse_q0     | 0.967    |\n",
            "| mse_q1     | 0.959    |\n",
            "| mse_q2     | 0.986    |\n",
            "| mse_q3     | 1.06     |\n",
            "| param_norm | 86.1     |\n",
            "| samples    | 8        |\n",
            "| step       | 0        |\n",
            "-------------------------\n",
            "saving model 0...\n",
            "saving model 0.9999...\n",
            "-------------------------\n",
            "| grad_norm  | 0.821    |\n",
            "| loss       | 0.986    |\n",
            "| loss_q0    | 0.984    |\n",
            "| loss_q1    | 0.971    |\n",
            "| loss_q2    | 0.986    |\n",
            "| loss_q3    | 1        |\n",
            "| mse        | 0.986    |\n",
            "| mse_q0     | 0.984    |\n",
            "| mse_q1     | 0.971    |\n",
            "| mse_q2     | 0.986    |\n",
            "| mse_q3     | 1        |\n",
            "| param_norm | 86.1     |\n",
            "| samples    | 88       |\n",
            "| step       | 10       |\n",
            "-------------------------\n",
            "-------------------------\n",
            "| grad_norm  | 0.969    |\n",
            "| loss       | 0.983    |\n",
            "| loss_q0    | 0.983    |\n",
            "| loss_q1    | 0.991    |\n",
            "| loss_q2    | 0.971    |\n",
            "| loss_q3    | 0.983    |\n",
            "| mse        | 0.983    |\n",
            "| mse_q0     | 0.983    |\n",
            "| mse_q1     | 0.991    |\n",
            "| mse_q2     | 0.971    |\n",
            "| mse_q3     | 0.983    |\n",
            "| param_norm | 86.1     |\n",
            "| samples    | 168      |\n",
            "| step       | 20       |\n",
            "-------------------------\n",
            "-------------------------\n",
            "| grad_norm  | 1.07     |\n",
            "| loss       | 0.963    |\n",
            "| loss_q0    | 0.97     |\n",
            "| loss_q1    | 0.973    |\n",
            "| loss_q2    | 0.95     |\n",
            "| loss_q3    | 0.959    |\n",
            "| mse        | 0.963    |\n",
            "| mse_q0     | 0.97     |\n",
            "| mse_q1     | 0.973    |\n",
            "| mse_q2     | 0.95     |\n",
            "| mse_q3     | 0.959    |\n",
            "| param_norm | 86.1     |\n",
            "| samples    | 248      |\n",
            "| step       | 30       |\n",
            "-------------------------\n",
            "-------------------------\n",
            "| grad_norm  | 0.968    |\n",
            "| loss       | 0.941    |\n",
            "| loss_q0    | 0.97     |\n",
            "| loss_q1    | 0.971    |\n",
            "| loss_q2    | 0.922    |\n",
            "| loss_q3    | 0.899    |\n",
            "| mse        | 0.941    |\n",
            "| mse_q0     | 0.97     |\n",
            "| mse_q1     | 0.971    |\n",
            "| mse_q2     | 0.922    |\n",
            "| mse_q3     | 0.899    |\n",
            "| param_norm | 86.1     |\n",
            "| samples    | 328      |\n",
            "| step       | 40       |\n",
            "-------------------------\n",
            "-------------------------\n",
            "| grad_norm  | 1.24     |\n",
            "| loss       | 0.922    |\n",
            "| loss_q0    | 0.986    |\n",
            "| loss_q1    | 0.934    |\n",
            "| loss_q2    | 0.892    |\n",
            "| loss_q3    | 0.889    |\n",
            "| mse        | 0.922    |\n",
            "| mse_q0     | 0.986    |\n",
            "| mse_q1     | 0.934    |\n",
            "| mse_q2     | 0.892    |\n",
            "| mse_q3     | 0.889    |\n",
            "| param_norm | 86.1     |\n",
            "| samples    | 408      |\n",
            "| step       | 50       |\n",
            "-------------------------\n",
            "[rank0]: Traceback (most recent call last):\n",
            "[rank0]:   File \"/content/diffusion-lagr/scripts/turb_train.py\", line 84, in <module>\n",
            "[rank0]:     main()\n",
            "[rank0]:   File \"/content/diffusion-lagr/scripts/turb_train.py\", line 57, in main\n",
            "[rank0]:     ).run_loop()\n",
            "[rank0]:       ^^^^^^^^^^\n",
            "[rank0]:   File \"/content/diffusion-lagr/guided_diffusion/train_util.py\", line 159, in run_loop\n",
            "[rank0]:     self.run_step(batch, cond)\n",
            "[rank0]:   File \"/content/diffusion-lagr/guided_diffusion/train_util.py\", line 173, in run_step\n",
            "[rank0]:     self.forward_backward(batch, cond)\n",
            "[rank0]:   File \"/content/diffusion-lagr/guided_diffusion/train_util.py\", line 214, in forward_backward\n",
            "[rank0]:     self.mp_trainer.backward(loss)\n",
            "[rank0]:   File \"/content/diffusion-lagr/guided_diffusion/fp16_util.py\", line 181, in backward\n",
            "[rank0]:     loss.backward()\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
            "[rank0]:     torch.autograd.backward(\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "[rank0]:     _engine_run_backward(\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
            "[rank0]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]: KeyboardInterrupt\n",
            "[rank0]:[W328 15:23:21.582707811 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
          ]
        }
      ],
      "source": [
        "# Training command\n",
        "!python scripts/turb_train.py $DATA_FLAGS $MODEL_FLAGS $DIFFUSION_FLAGS $TRAIN_FLAGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LGjhmW8Ea_mH"
      },
      "outputs": [],
      "source": [
        "# Set sampling flags\n",
        "SAMPLE_FLAGS=\"--num_samples 16 --batch_size 8 --model_path /content/drive/MyDrive/diff-lagr/model_checkpoints/ema_0.9999_000000.pt\"\n",
        "\n",
        "#Please note that the $MODEL_FLAGS and $DIFFUSION_FLAGS should be the same as those used in training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIljY7aaa5o0",
        "outputId": "783e1018-8b5c-4db7-d461-4c99201f0703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging to /tmp/openai-2025-03-28-15-25-34-177415\n",
            "creating model and diffusion...\n",
            "sampling...\n",
            "created 8 samples\n",
            "created 16 samples\n",
            "saving to /content/drive/MyDrive/diff-lagr/samples/samples_16x300x3.npz\n",
            "sampling complete\n",
            "[rank0]:[W328 15:26:10.080216368 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
          ]
        }
      ],
      "source": [
        "# Sampling command\n",
        "!python scripts/turb_sample.py $SAMPLE_FLAGS $MODEL_FLAGS $DIFFUSION_FLAGS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7RNPQ9tbabI"
      },
      "outputs": [],
      "source": [
        "# After sampling with the above command, it will generate a file named samples_179200x2000x3.npz (for DM-3c as an example).\n",
        "# You can use the following code to read and retrieve the generated velocities:\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "with h5py.File('datasets/trajectories.h5', 'r') as h5f:\n",
        "    rx0 = np.array(h5f.get('min'))\n",
        "    rx1 = np.array(h5f.get('max'))\n",
        "\n",
        "u3c = (np.load('/content/drive/MyDrive/diff-lagr/samples/samples_16x300x3.npz')['arr_0']+1)*(rx1-rx0)/2 + rx0\n",
        "# save u3c as a file\n",
        "np.save('/content/drive/MyDrive/diff-lagr/samples/u3c_samples_16x300x3.npy', u3c)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}